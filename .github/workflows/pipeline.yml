name: Data Pipeline

on:
  schedule:
    - cron: '0 * * *'  # Каждый час
  workflow_dispatch:  # Ручной запуск

jobs:
  build:
    runs-on: ubuntu-latest
    env:  # Глобальные переменные окружения
      OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
      # Добавьте другие секреты, если нужны (e.g., DATABASE_URL: ${{ secrets.DATABASE_URL }})

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        submodules: false
        token: ${{ secrets.REPO_ACCESS_TOKEN }}  # Используем PAT для push прав
        fetch-depth: 0  # Полная история для корректного merge/pull

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'  # Или ваша версия, Prophet требует 3.7+

    # Новый шаг: Pull с rebase в начале, чтобы синхронизировать локальную ветку с удалённой перед любыми изменениями.
    # Это предотвратит ошибку non-fast-forward, если предыдущий run запушил изменения.
    - name: Pull latest changes to avoid stale info
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git pull --rebase origin ${{ github.ref_name }} || (echo "Rebase failed, check for conflicts" && exit 1)

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt  # Если есть requirements.txt
        pip install tabulate  # Добавлено для исправления ошибки в update_readme.py
        # Или напрямую: pip install prophet
        # pip install -r requirements.txt  # Удалено дублирование
    - name: Create data directories
      run: |
        mkdir -p data/raw/openweather_api data/models data/models/forecast data/visualizations || echo "Failed to create directories"
    # Проверка API-ключа перед сбором данных
    - name: Check if API key is available
      id: check_api
      run: |
        if [ -n "$OPENWEATHER_API_KEY" ]; then
          echo "has_api_key=true" >> $GITHUB_OUTPUT
        else
          echo "has_api_key=false" >> $GITHUB_OUTPUT
          echo "API key not available. Skipping data collection."
        fi
    - name: Run data collection
      if: steps.check_api.outputs.has_api_key == 'true'
      run: |
        python scripts/collect_data.py || echo "Data collection script failed"
    - name: Verify files after collection
      run: |
        echo "Contents of data/ after collection:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f -name "*.json" | head -10 || echo "No JSON files found"
    - name: Upload data files as artifact after collection
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-collection
        path: data/
        if-no-files-found: warn

    # Проверка наличия сырых файлов перед очисткой
    - name: Check if raw files exist for cleaning
      id: check_raw
      run: |
        if [ -n "$(find data/ -type f -name "*.json" | head -1)" ]; then
          echo "has_raw_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_raw_files=false" >> $GITHUB_OUTPUT
          echo "No raw files found. Skipping data cleaning."
        fi
    - name: Run data cleaning
      if: steps.check_raw.outputs.has_raw_files == 'true'
      run: |
        python scripts/clean_data.py || echo "Data cleaning script failed"
    - name: Verify files after cleaning
      run: |
        echo "Contents of data/ after cleaning:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"
    - name: Upload data files as artifact after cleaning
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-cleaning
        path: data/
        if-no-files-found: warn

    # Проверка наличия файлов после очистки перед обогащением
    - name: Check if cleaned files exist for enrichment
      id: check_cleaned
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_cleaned_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_cleaned_files=false" >> $GITHUB_OUTPUT
          echo "No cleaned files found. Skipping data enrichment."
        fi
    - name: Run data enrichment
      if: steps.check_cleaned.outputs.has_cleaned_files == 'true'
      run: |
        python scripts/enrich_data.py || echo "Data enrichment script failed"
    - name: Verify files after enrichment
      run: |
        echo "Contents of data/ after enrichment:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"
    - name: Upload data files as artifact after enrichment
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-enrichment
        path: data/
        if-no-files-found: warn

    # Проверка наличия файлов после обогащения перед созданием отчётов
    - name: Check if enriched files exist for reports
      id: check_enriched
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_enriched_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_enriched_files=false" >> $GITHUB_OUTPUT
          echo "No enriched files found. Skipping report creation."
        fi
    - name: Run report creation
      if: steps.check_enriched.outputs.has_enriched_files == 'true'
      run: |
        python scripts/create_reports.py || echo "Report creation script failed"
    - name: Verify files after reports
      run: |
        echo "Contents of data/ after reports:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"
    - name: Upload data files as artifact after reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-reports
        path: data/
        if-no-files-found: warn

    - name: Upload full logs as artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: workflow-logs
        path: .  # Или укажите конкретный файл логов, если скрипты пишут в него
        if-no-files-found: warn

    # Проверка наличия файлов после отчётов перед обучением
    - name: Check if files exist for training
      id: check_for_train
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_files_for_train=true" >> $GITHUB_OUTPUT
        else
          echo "has_files_for_train=false" >> $GITHUB_OUTPUT
          echo "No files found after reports. Skipping training."
        fi
    - name: Train weather model and generate forecasts
      if: steps.check_for_train.outputs.has_files_for_train == 'true'
      run: |
        python scripts/train_weather_model.py  # Исправлено: скрипт в scripts/, запускает обучение, прогноз и визуализации
    - name: Check directories
      run: |
        echo "Checking data/ directory:"
        ls -la data/ || echo "data/ directory not found"
        echo "Checking data/models/ directory:"
        ls -la data/models/ || echo "data/models/ directory does not exist or is empty"
        echo "Checking data/models/forecast/ directory:"
        ls -la data/models/forecast/ || echo "data/models/forecast/ directory does not exist or is empty"
        echo "Checking data/visualizations/ directory:"
        ls -la data/visualizations/ || echo "data/visualizations/ directory does not exist or is empty"
    - name: Verify files after reports
      run: |
        echo "Contents of data/ after reports:"
        ls -la data/ || echo "Data directory not found"
        echo "All files in data/ (sorted by modification time):"
        find data/ -type f -printf '%T@ %p\n' | sort -n | cut -d' ' -f2- || echo "No files found"
        echo "Aggregated files specifically:"
        find data/aggregated/ -type f || echo "No aggregated files found"

    # Новый шаг: Проверка наличия aggregated файлов перед генерацией визуализаций
    - name: Check if aggregated files exist for visualizations
      id: check_aggregated
      run: |
        if [ -n "$(find data/aggregated -type f | head -1)" ]; then
          echo "has_aggregated_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_aggregated_files=false" >> $GITHUB_OUTPUT
          echo "No aggregated files found. Skipping visualizations."
        fi
    # Новый шаг: Генерация визуализаций из generate_visualizations.py
    - name: Generate visualizations
      if: steps.check_aggregated.outputs.has_aggregated_files == 'true'
      run: |
        python scripts/generate_visualizations.py || echo "Visualization generation failed"
    # Новый шаг: Проверка файлов после генерации визуализаций
    - name: Verify files after visualizations
      run: |
        echo "Contents of data/visualizations/ after visualizations:"
        ls -la data/visualizations/ || echo "data/visualizations/ directory not found"
        find data/visualizations/ -type f | head -10 || echo "No visualization files found"

    # Новый шаг: Обновление README с погодными данными (заменяет старый шаг "Update README with visualizations")
    - name: Update README with weather data
      run: |
        python scripts/update_readme.py || echo "Failed to update README"

    - name: Add, commit, and push changes
      run: |
        git add .  # Добавляет все изменения (модели, визуализации, README и т.д.)
        git status  # Покажет, что добавлено
        if ! git diff --staged --quiet; then
          git commit -m "Update forecasts, visualizations, and README"
          # Убираем --force-with-lease, чтобы избежать перезаписи; используем обычный push
          git push https://${{ github.actor }}:${{ secrets.REPO_ACCESS_TOKEN }}@github.com/${{ github.repository }}.git ${{ github.ref_name }}
          echo "Changes committed and pushed."
        else
          echo "No changes to commit."
        fi
    - name: Verify push
      run: echo "Workflow completed. Check repository for changes."
