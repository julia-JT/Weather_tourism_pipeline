name: Data Pipeline_main

on:
  schedule:
    - cron: "0 * * * *"  # Каждый час
  workflow_dispatch:  # Ручной запуск

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Добавлено для push (обязательно)
    env:  # Глобальные переменные окружения
      OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
      # Добавьте другие секреты, если нужны (e.g., DATABASE_URL: ${{ secrets.DATABASE_URL }})

    steps:
    - name: Checkout code
      id: checkout
      uses: actions/checkout@v4
      with:
        submodules: false
        token: ${{ secrets.REPO_ACCESS_TOKEN }}  # PAT с scope 'repo' для полного доступа
        fetch-depth: 0  # Полная история для корректного merge/pull

    - name: Set up Python
      id: setup_python
      if: steps.checkout.outcome == 'success'
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'  # Или ваша версия, Prophet требует 3.7+

    # Удалён ранний pull_changes: он конфликтует с commit_push в конце (где pull уже есть).
    # Если нужен pull для синхронизации кода, добавьте его здесь, но с осторожностью (если код меняется в репо, может быть конфликт).
    # Для этого пайплайна ранний pull не обязателен, поскольку скрипты фиксированы.

    - name: Install dependencies
      id: install_deps
      if: steps.setup_python.outcome == 'success'
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt  # Если есть requirements.txt
        pip install tabulate  # Добавлено для исправления ошибки в update_readme.py
        pip install plotly
        python -m pip install --upgrade pip
        # Или напрямую: pip install prophet

    - name: Create data directories
      id: create_dirs
      if: steps.install_deps.outcome == 'success'
      run: |
        mkdir -p data/raw/openweather_api data/models data/models/forecast data/visualizations || echo "Failed to create directories"

    - name: Check if API key is available
      id: check_api
      if: steps.create_dirs.outcome == 'success'
      run: |
        if [ -n "$OPENWEATHER_API_KEY" ]; then
          echo "has_api_key=true" >> $GITHUB_OUTPUT
        else
          echo "has_api_key=false" >> $GITHUB_OUTPUT
          echo "API key not available. Skipping data collection."
        fi

    - name: Run data collection
      id: run_collection
      if: steps.check_api.outcome == 'success' && steps.check_api.outputs.has_api_key == 'true'
      run: |
        python scripts/collect_data.py || echo "Data collection script failed"

    - name: Verify files after collection
      id: verify_collection
      if: steps.run_collection.outcome == 'success'
      run: |
        echo "Contents of data/ after collection:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f -name "*.json" | head -10 || echo "No JSON files found"

    - name: Upload data files as artifact after collection
      id: upload_collection
      if: steps.verify_collection.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-collection
        path: data/
        if-no-files-found: warn

    - name: Check if raw files exist for cleaning
      id: check_raw
      if: steps.upload_collection.outcome == 'success'
      run: |
        if [ -n "$(find data/ -type f -name "*.json" | head -1)" ]; then
          echo "has_raw_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_raw_files=false" >> $GITHUB_OUTPUT
          echo "No raw files found. Skipping data cleaning."
        fi

    - name: Run data cleaning
      id: run_cleaning
      if: steps.check_raw.outcome == 'success' && steps.check_raw.outputs.has_raw_files == 'true'
      run: |
        python scripts/clean_data.py || echo "Data cleaning script failed"

    - name: Verify files after cleaning
      id: verify_cleaning
      if: steps.run_cleaning.outcome == 'success'
      run: |
        echo "Contents of data/ after cleaning:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"

    - name: Upload data files as artifact after cleaning
      id: upload_cleaning
      if: steps.verify_cleaning.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-cleaning
        path: data/
        if-no-files-found: warn

    - name: Check if cleaned files exist for enrichment
      id: check_cleaned
      if: steps.upload_cleaning.outcome == 'success'
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_cleaned_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_cleaned_files=false" >> $GITHUB_OUTPUT
          echo "No cleaned files found. Skipping data enrichment."
        fi

    - name: Run data enrichment
      id: run_enrichment
      if: steps.check_cleaned.outcome == 'success' && steps.check_cleaned.outputs.has_cleaned_files == 'true'
      run: |
        python scripts/enrich_data.py || echo "Data enrichment script failed"

    - name: Verify files after enrichment
      id: verify_enrichment
      if: steps.run_enrichment.outcome == 'success'
      run: |
        echo "Contents of data/ after enrichment:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"

    - name: Upload data files as artifact after enrichment
      id: upload_enrichment
      if: steps.verify_enrichment.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-enrichment
        path: data/
        if-no-files-found: warn

    - name: Check if enriched files exist for reports
      id: check_enriched
      if: steps.upload_enrichment.outcome == 'success'
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_enriched_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_enriched_files=false" >> $GITHUB_OUTPUT
          echo "No enriched files found. Skipping report creation."
        fi

    - name: Run report creation
      id: run_reports
      if: steps.check_enriched.outcome == 'success' && steps.check_enriched.outputs.has_enriched_files == 'true'
      run: |
        python scripts/create_reports.py || echo "Report creation script failed"

    - name: Verify files after reports
      id: verify_reports
      if: steps.run_reports.outcome == 'success'
      run: |
        echo "Contents of data/ after reports:"
        ls -la data/ || echo "Data directory not found"
        find data/ -type f | head -10 || echo "No files found"

    - name: Upload data files as artifact after reports
      id: upload_reports
      if: steps.verify_reports.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: collected-data-after-reports
        path: data/
        if-no-files-found: warn

    - name: Upload full logs as artifact
      id: upload_logs
      if: steps.upload_reports.outcome == 'success'
      uses: actions/upload-artifact@v4
      with:
        name: workflow-logs
        path: .  # Или укажите конкретный файл логов, если скрипты пишут в него
        if-no-files-found: warn

    - name: Check if files exist for training
      id: check_for_train
      if: steps.upload_logs.outcome == 'success'
      run: |
        if [ -n "$(find data/ -type f | head -1)" ]; then
          echo "has_files_for_train=true" >> $GITHUB_OUTPUT
        else
          echo "has_files_for_train=false" >> $GITHUB_OUTPUT
          echo "No files found after reports. Skipping training."
        fi

    - name: Train weather model and generate forecasts
      id: train_model
      if: steps.check_for_train.outcome == 'success' && steps.check_for_train.outputs.has_files_for_train == 'true'
      run: |
        python scripts/train_weather_model.py  # Исправлено: скрипт в scripts/, запускает обучение, прогноз и визуализации

    - name: Check directories
      id: check_dirs
      if: steps.train_model.outcome == 'success'
      run: |
        echo "Checking data/ directory:"
        ls -la data/ || echo "data/ directory not found"
        echo "Checking data/models/ directory:"
        ls -la data/models/ || echo "data/models/ directory does not exist or is empty"
        echo "Checking data/models/forecast/ directory:"
        ls -la data/models/forecast/ || echo "data/models/forecast/ directory does not exist or is empty"
        echo "Checking data/visualizations/ directory:"
        ls -la data/visualizations/ || echo "data/visualizations/ directory does not exist or is empty"

    - name: Verify files after reports
      id: verify_after_train
      if: steps.check_dirs.outcome == 'success'
      run: |
        echo "Contents of data/ after reports:"
        ls -la data/ || echo "Data directory not found"
        echo "All files in data/ (sorted by modification time):"
        find data/ -type f -printf '%T@ %p\n' | sort -n | cut -d' ' -f2- || echo "No files found"
        echo "Aggregated files specifically:"
        find data/aggregated/ -type f || echo "No aggregated files found"

    - name: Check if aggregated files exist for visualizations
      id: check_aggregated
      if: steps.verify_after_train.outcome == 'success'
      run: |
        if [ -n "$(find data/aggregated -type f | head -1)" ]; then
          echo "has_aggregated_files=true" >> $GITHUB_OUTPUT
        else
          echo "has_aggregated_files=false" >> $GITHUB_OUTPUT
          echo "No aggregated files found. Skipping visualizations."
        fi

    - name: Generate visualizations
      id: generate_viz
      if: steps.check_aggregated.outcome == 'success' && steps.check_aggregated.outputs.has_aggregated_files == 'true'
      run: |
        python scripts/generate_visualizations.py || echo "Visualization generation failed"

    - name: Verify files after visualizations
      id: verify_viz
      if: steps.generate_viz.outcome == 'success'
      run: |
        echo "Contents of data/visualizations/ after visualizations:"
        ls -la data/visualizations/ || echo "data/visualizations/ directory not found"
        find data/visualizations/ -type f | head -10 || echo "No visualization files found"

    - name: Update README with weather data
      id: update_readme
      if: steps.verify_viz.outcome == 'success'
      run: |
        python scripts/update_readme.py || echo "Failed to update README"

    - name: Add, commit, and push changes
      id: commit_push
      if: steps.update_readme.outcome == 'success'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git status
        echo "Remote info:"
        git remote -v
        echo "Remote branches:"
        git branch -r
        git add .
        if ! git diff --staged --quiet; then
          git commit -m "Automated update: weather data, models, and reports"
        fi
        git fetch origin
        echo "Attempting pull --rebase..."
        if git pull --rebase origin/${{ github.ref_name }}; then
          echo "Pull succeeded"
        else
          echo "Pull failed, proceeding to push (assuming local is ahead)"
          # Fallback: Если pull fail'ится, но fetch OK, попробуем push (если remote не имеет новых изменений)
        fi
        # Повторный add/commit на случай изменений после pull
        git add .
        if ! git diff --staged --quiet; then
          git commit -m "Additional updates after rebase"
        fi
        git push origin ${{ github.ref_name }}

    - name: Verify push
      if: steps.commit_push.outcome == 'success'
      run: echo "Workflow completed. Check repository for changes."
