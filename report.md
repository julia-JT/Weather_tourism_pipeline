1. Описание процесса
• Какие города выбрали и почему?
    Города взяла из реккомендации, понравился разброс по разным федеральным округам и разным погодным условиям.
• Какие проблемы встретили при сборе данных?
    При сборе данных хотелось большых данных, но сайт дает только погоду на сейчас в стандартном запросе, однако,
    можно затянуть их прогнозные значения, но т.к. прогноз нужно сформировать самим, то это делать не стала
• Какие правила очистки применили?
    Не все данные взяла, часть оказались или пустыми (pop и пр.), часть не было указано в задаче.
    Логика слоя очистки заключалась в объединении данных по дате в отдельный файл. Далее эта логика сохранится до слоя с отчетами.
3. Анализ результатов
• В каком городе самая комфортная погода для туристов?
    На момент написания этого резюме, реккомендованного города нет, в Сочи был дождь, а так этот город оставался единственным по реккомендациям.
• Какие федеральные округа наиболее привлекательны?
    По привлекательности округов исходя из пункта выше также ничего выделить не получилось.
• Какие рекомендации дали бы турагентствам?
    В России сложно угодать погоду, особенно осенью, либо дождь, либо холодно или пасмурно и т.п.
   Чаще всего индекс привлекательности сильно зависил от сезонов в каждом городе + погоды, эти условия на сейчас не реккомендуют наши города).
5. Архитектурные решения
• Почему выбрали именно такую структуру папок?
  Эта структура изначально была заложена в задании, но были добавлены дополнительные папки для модели, прогнозов и визуализаций, счетаю их логичными.
• Какие метаданные считаете самыми важными?
   Даты получения данных и их загрузки, индексы, собранные на основе разных факторов, даты в названии файлов(удобно раскапывать ошибки)
• Как бы масштабировали решение на 100 городов?
  Масштабирование достаточно простое, в 2х скриптах меняются перечисляемые города и все работает, но может возникнуть сложность в ориентации внутри
  групп, где город указан в названии файла, но там тоже можно сделать папки с градациями.
7. Выводы и улучшения
• Что можно улучшить в пайплайне?
  Придумать более сложную систему присвоения рейтинга и расчета индексов, сейчас она примитивна. Доразобрать текущие ошибки в формировании визуализаций 
  generate_visualizations.py, пока не побеждены. Визуализации строятся на основании расчета модели и отображения сводных данных витрин.
  Добавить прогнозы API и сравнить их с моделью.
• Какие дополнительные данные хотели бы добавить?
  Добавить прогнозы API и сравнить их с моделью.
• Как автоматизировать процесс?
  Процесс автоматизирован, запускается каждый час по расписанию, но т.к. ресурсы гитхаба не безграничны, пайплайн в таком режиме будет работать 
  пока не закончится место.

В папке scripts есть Rest_api: rest_api_py
